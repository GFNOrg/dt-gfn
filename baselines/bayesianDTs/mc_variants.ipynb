{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running experiment on Wine dataset...\n",
      "\n",
      "Running with seed 1\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 1 - Accuracy: 0.9722, Nodes: 17.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 1 - Accuracy: 0.9722, Nodes: 16.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 1 - Accuracy: 0.9537, Nodes: 15.666666666666666\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 1 - Accuracy: 0.9444, Nodes: 16.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 1 - Accuracy: 0.9500, Nodes: 15.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 1 - Accuracy: 0.9444, Nodes: 15.666666666666666\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 1 - Accuracy: 0.9444, Nodes: 15.571428571428571\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 1 - Accuracy: 0.9444, Nodes: 15.75\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 1 - Accuracy: 0.9383, Nodes: 15.88888888888889\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 1 - Accuracy: 0.9361, Nodes: 16.0\n",
      "\n",
      "Running with seed 2\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 2 - Accuracy: 0.9167, Nodes: 13.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 2 - Accuracy: 0.9167, Nodes: 14.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 2 - Accuracy: 0.9352, Nodes: 13.666666666666666\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 2 - Accuracy: 0.9375, Nodes: 14.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 2 - Accuracy: 0.9444, Nodes: 14.2\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 2 - Accuracy: 0.9537, Nodes: 14.666666666666666\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 2 - Accuracy: 0.9603, Nodes: 14.714285714285714\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 2 - Accuracy: 0.9583, Nodes: 14.25\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 2 - Accuracy: 0.9568, Nodes: 14.333333333333334\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 2 - Accuracy: 0.9528, Nodes: 14.4\n",
      "\n",
      "Running with seed 3\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 3 - Accuracy: 0.9444, Nodes: 13.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 3 - Accuracy: 0.9444, Nodes: 15.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 3 - Accuracy: 0.9537, Nodes: 15.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 3 - Accuracy: 0.9583, Nodes: 15.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 3 - Accuracy: 0.9556, Nodes: 14.6\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 3 - Accuracy: 0.9491, Nodes: 14.333333333333334\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 3 - Accuracy: 0.9524, Nodes: 14.142857142857142\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 3 - Accuracy: 0.9549, Nodes: 14.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 3 - Accuracy: 0.9506, Nodes: 14.11111111111111\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 3 - Accuracy: 0.9500, Nodes: 14.2\n",
      "\n",
      "Running with seed 4\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 4 - Accuracy: 0.9167, Nodes: 19.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 4 - Accuracy: 0.9583, Nodes: 17.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 4 - Accuracy: 0.9537, Nodes: 17.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 4 - Accuracy: 0.9514, Nodes: 16.5\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 4 - Accuracy: 0.9611, Nodes: 16.2\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 4 - Accuracy: 0.9630, Nodes: 16.333333333333332\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 4 - Accuracy: 0.9683, Nodes: 15.857142857142858\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 4 - Accuracy: 0.9722, Nodes: 15.5\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 4 - Accuracy: 0.9691, Nodes: 14.777777777777779\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 4 - Accuracy: 0.9694, Nodes: 14.8\n",
      "\n",
      "Running with seed 5\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 5 - Accuracy: 0.8056, Nodes: 23.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 5 - Accuracy: 0.8333, Nodes: 24.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 5 - Accuracy: 0.8241, Nodes: 24.333333333333332\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 5 - Accuracy: 0.8472, Nodes: 21.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 5 - Accuracy: 0.8500, Nodes: 21.4\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 5 - Accuracy: 0.8657, Nodes: 19.666666666666668\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 5 - Accuracy: 0.8730, Nodes: 18.428571428571427\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 5 - Accuracy: 0.8681, Nodes: 19.0\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 5 - Accuracy: 0.8765, Nodes: 18.11111111111111\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Seed 5 - Accuracy: 0.8833, Nodes: 17.4\n",
      "Wine - Mean Accuracy: 0.9311, Std: 0.0425\n",
      "Wine - Mean Nodes: 16.25, Std: 2.66\n",
      "\n",
      "Final Results:\n",
      "Wine:\n",
      "  Accuracy - Mean: 0.9311, Std: 0.0425\n",
      "  Nodes    - Mean: 16.25, Std: 2.66\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from typing import List, Dict\n",
    "from scipy.special import gammaln\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "class SMCDecisionTree:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2, n_particles=10, alpha_value=0.1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.n_particles = n_particles\n",
    "        self.tree = None\n",
    "        self.alpha_value = alpha_value\n",
    "\n",
    "    def _log_dirichlet(self, dirichlet_params):\n",
    "        return np.sum(gammaln(dirichlet_params)) - gammaln(np.sum(dirichlet_params)) \n",
    "\n",
    "    def _initialize_particles(self, n_features):\n",
    "        return {\n",
    "            'feature_index': np.random.randint(0, n_features, self.n_particles),\n",
    "            'threshold': np.random.uniform(0, 1, self.n_particles)\n",
    "        }\n",
    "\n",
    "    def _move_particles(self, particles, n_features):\n",
    "        move_mask = np.random.random(self.n_particles) < 0.5\n",
    "        particles['feature_index'][move_mask] = np.random.randint(0, n_features, np.sum(move_mask))\n",
    "        particles['threshold'][~move_mask] += np.random.normal(0, 0.1, np.sum(~move_mask))\n",
    "        return particles\n",
    "\n",
    "    def _evaluate_split(self, X, y, feature_index, threshold):\n",
    "        left_mask = X[:, feature_index] <= threshold\n",
    "        left_y, right_y = y[left_mask], y[~left_mask]\n",
    "        \n",
    "        if len(left_y) == 0 or len(right_y) == 0:\n",
    "            return -np.inf\n",
    "        \n",
    "        left_counts = np.zeros(len(self.classes_))\n",
    "        right_counts = np.zeros(len(self.classes_))\n",
    "        \n",
    "        for i, c in enumerate(self.classes_):\n",
    "            left_counts[i] = np.sum(left_y == c)\n",
    "            right_counts[i] = np.sum(right_y == c)\n",
    "        \n",
    "        alpha = np.ones(len(self.classes_)) * self.alpha_value\n",
    "        \n",
    "        log_likelihood = (\n",
    "            self._log_dirichlet(left_counts + alpha) - self._log_dirichlet(alpha) +\n",
    "            self._log_dirichlet(right_counts + alpha) - self._log_dirichlet(alpha)\n",
    "        )\n",
    "        \n",
    "        log_prior = 0 # -(np.log2(4) + np.log2(X.shape[1]))*self.num_nodes()\n",
    "         \n",
    "        return log_likelihood + log_prior\n",
    "\n",
    "    def _smc_split(self, X, y):\n",
    "        particles = self._initialize_particles(X.shape[1])\n",
    "        \n",
    "        for _ in range(5):  # Number of SMC iterations\n",
    "            particles = self._move_particles(particles, X.shape[1])\n",
    "            \n",
    "            weights = np.array([self._evaluate_split(X, y, p_f, p_t) \n",
    "                                for p_f, p_t in zip(particles['feature_index'], particles['threshold'])])\n",
    "            weights = np.where(np.isfinite(weights), np.exp(weights), 0)\n",
    "            \n",
    "            # Handle potential zero sum of weights\n",
    "            if np.sum(weights) == 0:\n",
    "                weights = np.ones_like(weights) / len(weights)\n",
    "            else:\n",
    "                weights /= np.sum(weights)\n",
    "            \n",
    "            # Check for NaN values and replace with uniform probabilities if necessary\n",
    "            if np.any(np.isnan(weights)):\n",
    "                print(\"Warning: NaN weights encountered. Using uniform probabilities.\")\n",
    "                weights = np.ones_like(weights) / len(weights)\n",
    "            \n",
    "            indices = np.random.choice(self.n_particles, size=self.n_particles, p=weights)\n",
    "            particles = {k: v[indices] for k, v in particles.items()}\n",
    "        \n",
    "        best_index = np.argmax(weights)\n",
    "        return particles['feature_index'][best_index], particles['threshold'][best_index]\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        unique_classes = np.unique(y)\n",
    "\n",
    "        if depth >= self.max_depth or n_samples < self.min_samples_split or len(unique_classes) == 1:\n",
    "            counts = np.zeros(len(self.classes_))\n",
    "            for i, c in enumerate(self.classes_):\n",
    "                counts[i] = np.sum(y == c)\n",
    "            return Node(value=counts)\n",
    "\n",
    "        feature_index, threshold = self._smc_split(X, y)\n",
    "        \n",
    "        left_mask = X[:, feature_index] <= threshold\n",
    "        X_left, y_left = X[left_mask], y[left_mask]\n",
    "        X_right, y_right = X[~left_mask], y[~left_mask]\n",
    "        \n",
    "        left_subtree = self._grow_tree(X_left, y_left, depth + 1)\n",
    "        right_subtree = self._grow_tree(X_right, y_right, depth + 1)\n",
    "\n",
    "        return Node(feature_index=feature_index, threshold=threshold, left=left_subtree, right=right_subtree)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_features = X.shape[1]\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.n_classes = len(self.classes_)\n",
    "        print(f\"Number of classes: {self.n_classes}\")\n",
    "        print(f\"Unique classes: {self.classes_}\")\n",
    "        print(f\"Input y shape: {y.shape}\")\n",
    "        print(f\"Input y unique values: {np.unique(y)}\")\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "\n",
    "    def _predict_sample(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return self.classes_[np.argmax(node.value)]\n",
    "        \n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self._predict_sample(x, node.left)\n",
    "        else:\n",
    "            return self._predict_sample(x, node.right)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_sample(x, self.tree) for x in X])\n",
    "\n",
    "    def num_nodes(self):\n",
    "        return self._count_nodes(self.tree)\n",
    "\n",
    "    def _count_nodes(self, node):\n",
    "        if node is None:\n",
    "            return 0\n",
    "        return 1 + self._count_nodes(node.left) + self._count_nodes(node.right)\n",
    "\n",
    "def run_smc_dt_on_dataset(X_train, y_train, X_test, y_test, seed=42):\n",
    "    try:\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        smc_dt = SMCDecisionTree(max_depth=5, n_particles=100)\n",
    "        smc_dt.fit(X_train_scaled, y_train)\n",
    "\n",
    "        y_pred = smc_dt.predict(X_test_scaled)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        return accuracy, smc_dt.num_nodes()\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "def experiment_on_datasets(seeds: List[int], n_trials=10, UCI=True) -> Dict[str, Dict[str, float]]:\n",
    "    if UCI:\n",
    "        datasets = [\n",
    "            #(17, \"BCW-D\"),\n",
    "            (109, \"Wine\"),\n",
    "            # (53, \"Iris\"),\n",
    "            # (850, \"Raisin\"),\n",
    "        ]\n",
    "    else:\n",
    "        # Specify CSV files directly\n",
    "        datasets = [\n",
    "            # (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor.csv\", \"HiddenXOR\"),\n",
    "            # (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/S1.csv\", \"BasicSanityCheck\"), \n",
    "            # (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/S2.csv\", \"HarderSanityCheck\")\n",
    "            (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_lv1.csv\", \"HiddenXORLV1\"),\n",
    "            (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_lv2.csv\", \"HiddenXORLV2\"),\n",
    "            (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_lv3.csv\", \"HiddenXORLV3\"),\n",
    "            (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_real_lv1.csv\", \"HiddenXORLV1Real\"),\n",
    "            (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_real_lv2.csv\", \"HiddenXORLV2Real\"),\n",
    "            (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_real_lv3.csv\", \"HiddenXORLV3Real\")\n",
    "        ]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for dataset_info in datasets:\n",
    "        if UCI:\n",
    "            dataset_id, dataset_name = dataset_info\n",
    "            print(f\"\\nRunning experiment on {dataset_name} dataset...\")\n",
    "            dataset = fetch_ucirepo(id=dataset_id)\n",
    "            X = dataset.data.features.values\n",
    "            y = dataset.data.targets.values.ravel()\n",
    "        else:\n",
    "            file_path, dataset_name = dataset_info\n",
    "            print(f\"\\nRunning experiment on {dataset_name} dataset from {file_path}...\")\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"File {file_path} not found.\")\n",
    "                continue\n",
    "            data = pd.read_csv(file_path)\n",
    "            X = data.iloc[:, :-2].values  # Assuming last two columns are 'train'/'test' and the target\n",
    "            y = data.iloc[:, -2].values\n",
    "            split_column = data.iloc[:, -1].values  # 'train'/'test' column\n",
    "\n",
    "            # Split based on the 'train'/'test' column\n",
    "            X_train = X[split_column == 'train']\n",
    "            y_train = y[split_column == 'train']\n",
    "            X_test = X[split_column == 'test']\n",
    "            y_test = y[split_column == 'test']\n",
    "\n",
    "        # print(f\"Original y shape: {y.shape}\")\n",
    "        # print(f\"Original y unique values: {np.unique(y)}\")\n",
    "        \n",
    "        # print(f\"Dataset shape: {X.shape}\")\n",
    "        # print(f\"Unique classes in dataset: {np.unique(y)}\")\n",
    "        \n",
    "        accuracies = []\n",
    "        n_nodes_list = []\n",
    "        for seed in seeds:\n",
    "            print(f\"\\nRunning with seed {seed}\")\n",
    "            if UCI: \n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "            \n",
    "            if y_train.dtype == object:\n",
    "                le = LabelEncoder()\n",
    "                y_train = le.fit_transform(y_train)\n",
    "                y_test = le.transform(y_test)\n",
    "                # print(f\"After LabelEncoder - y_train unique values: {np.unique(y_train)}\")\n",
    "                # print(f\"After LabelEncoder - y_test unique values: {np.unique(y_test)}\")\n",
    "            try:\n",
    "                accs, sizes = [], []\n",
    "                for _ in range(n_trials):\n",
    "                    accuracy, n_nodes = run_smc_dt_on_dataset(X_train, y_train, X_test, y_test, seed)\n",
    "                    if accuracy is not None and n_nodes is not None:\n",
    "                        accs.append(accuracy)\n",
    "                        sizes.append(n_nodes)\n",
    "                    accuracies.append(np.mean(accs))\n",
    "                    n_nodes_list.append(np.mean(sizes))\n",
    "                    print(f\"Seed {seed} - Accuracy: {np.mean(accs):.4f}, Nodes: {np.mean(sizes)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred with seed {seed}: {str(e)}\")\n",
    "        \n",
    "        if accuracies and n_nodes_list:\n",
    "            mean_accuracy = np.mean(accuracies)\n",
    "            std_accuracy = np.std(accuracies)\n",
    "            mean_nodes = np.mean(n_nodes_list)\n",
    "            std_nodes = np.std(n_nodes_list)\n",
    "            \n",
    "            results[dataset_name] = {\n",
    "                \"mean_accuracy\": mean_accuracy,\n",
    "                \"std_accuracy\": std_accuracy,\n",
    "                \"mean_nodes\": mean_nodes,\n",
    "                \"std_nodes\": std_nodes\n",
    "            }\n",
    "            \n",
    "            print(f\"{dataset_name} - Mean Accuracy: {mean_accuracy:.4f}, Std: {std_accuracy:.4f}\")\n",
    "            print(f\"{dataset_name} - Mean Nodes: {mean_nodes:.2f}, Std: {std_nodes:.2f}\")\n",
    "        else:\n",
    "            print(f\"Failed to process {dataset_name} dataset\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the experiments\n",
    "seeds = np.array([1, 2, 3, 4, 5])  # Using multiple seeds for more robust results\n",
    "results = experiment_on_datasets(seeds, n_trials=10, UCI=True)\n",
    "\n",
    "# Print final results\n",
    "print(\"\\nFinal Results:\")\n",
    "for dataset, metrics in results.items():\n",
    "    print(f\"{dataset}:\")\n",
    "    print(f\"  Accuracy - Mean: {metrics['mean_accuracy']:.4f}, Std: {metrics['std_accuracy']:.4f}\")\n",
    "    print(f\"  Nodes    - Mean: {metrics['mean_nodes']:.2f}, Std: {metrics['std_nodes']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MCMC** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running experiment on HiddenXORLV1 dataset from /Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_lv1.csv...\n",
      "Original y shape: (1000,)\n",
      "Original y unique values: [0 1]\n",
      "Dataset shape: (1000, 5)\n",
      "Unique classes in dataset: [0 1]\n",
      "\n",
      "Running with seed 1\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 1.0000, Nodes: 15.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 1.0000, Nodes: 15.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 1.0000, Nodes: 15.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 1.0000, Nodes: 15.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 1.0000, Nodes: 15.0\n",
      "Seed 1 - Accuracy: 1.0000, Nodes: 15\n",
      "HiddenXORLV1 - Mean Accuracy: 1.0000, Std: 0.0000\n",
      "HiddenXORLV1 - Mean Nodes: 15.00, Std: 0.00\n",
      "\n",
      "Running experiment on HiddenXORLV2 dataset from /Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_lv2.csv...\n",
      "Original y shape: (1000,)\n",
      "Original y unique values: [0 1]\n",
      "Dataset shape: (1000, 20)\n",
      "Unique classes in dataset: [0 1]\n",
      "\n",
      "Running with seed 1\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.6267, Nodes: 55.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.6267, Nodes: 55.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.6267, Nodes: 55.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.6267, Nodes: 55.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.6267, Nodes: 55.0\n",
      "Seed 1 - Accuracy: 0.6267, Nodes: 55\n",
      "HiddenXORLV2 - Mean Accuracy: 0.6267, Std: 0.0000\n",
      "HiddenXORLV2 - Mean Nodes: 55.00, Std: 0.00\n",
      "\n",
      "Running experiment on HiddenXORLV3 dataset from /Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_lv3.csv...\n",
      "Original y shape: (1000,)\n",
      "Original y unique values: [0 1]\n",
      "Dataset shape: (1000, 30)\n",
      "Unique classes in dataset: [0 1]\n",
      "\n",
      "Running with seed 1\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.5500, Nodes: 63.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.5500, Nodes: 63.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.5500, Nodes: 63.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.5500, Nodes: 63.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.5500, Nodes: 63.0\n",
      "Seed 1 - Accuracy: 0.5500, Nodes: 63\n",
      "HiddenXORLV3 - Mean Accuracy: 0.5500, Std: 0.0000\n",
      "HiddenXORLV3 - Mean Nodes: 63.00, Std: 0.00\n",
      "\n",
      "Running experiment on HiddenXORLV1Real dataset from /Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_real_lv1.csv...\n",
      "Original y shape: (1000,)\n",
      "Original y unique values: [0 1]\n",
      "Dataset shape: (1000, 5)\n",
      "Unique classes in dataset: [0 1]\n",
      "\n",
      "Running with seed 1\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.5633, Nodes: 15.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.5567, Nodes: 15.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.5589, Nodes: 15.666666666666666\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.5600, Nodes: 16.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.5440, Nodes: 16.2\n",
      "Seed 1 - Accuracy: 0.4800, Nodes: 17\n",
      "HiddenXORLV1Real - Mean Accuracy: 0.5438, Std: 0.0292\n",
      "HiddenXORLV1Real - Mean Nodes: 15.81, Std: 0.70\n",
      "\n",
      "Running experiment on HiddenXORLV2Real dataset from /Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_real_lv2.csv...\n",
      "Original y shape: (1000,)\n",
      "Original y unique values: [0 1]\n",
      "Dataset shape: (1000, 10)\n",
      "Unique classes in dataset: [0 1]\n",
      "\n",
      "Running with seed 1\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.4667, Nodes: 19.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.4650, Nodes: 19.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.4678, Nodes: 19.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.4683, Nodes: 19.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.4693, Nodes: 19.4\n",
      "Seed 1 - Accuracy: 0.4733, Nodes: 21\n",
      "HiddenXORLV2Real - Mean Accuracy: 0.4684, Std: 0.0026\n",
      "HiddenXORLV2Real - Mean Nodes: 19.40, Std: 0.73\n",
      "\n",
      "Running experiment on HiddenXORLV3Real dataset from /Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_real_lv3.csv...\n",
      "Original y shape: (1000,)\n",
      "Original y unique values: [0 1]\n",
      "Dataset shape: (1000, 20)\n",
      "Unique classes in dataset: [0 1]\n",
      "\n",
      "Running with seed 1\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.5333, Nodes: 17.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.5333, Nodes: 17.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.5311, Nodes: 17.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.5317, Nodes: 17.0\n",
      "Number of classes: 2\n",
      "Unique classes: [0 1]\n",
      "Input y shape: (700,)\n",
      "Input y unique values: [0 1]\n",
      "Seed 1 - Accuracy: 0.5327, Nodes: 17.4\n",
      "Seed 1 - Accuracy: 0.5367, Nodes: 19\n",
      "HiddenXORLV3Real - Mean Accuracy: 0.5331, Std: 0.0018\n",
      "HiddenXORLV3Real - Mean Nodes: 17.40, Std: 0.73\n",
      "\n",
      "Final Results:\n",
      "HiddenXORLV1:\n",
      "  Accuracy - Mean: 1.0000, Std: 0.0000\n",
      "  Nodes    - Mean: 15.00, Std: 0.00\n",
      "HiddenXORLV2:\n",
      "  Accuracy - Mean: 0.6267, Std: 0.0000\n",
      "  Nodes    - Mean: 55.00, Std: 0.00\n",
      "HiddenXORLV3:\n",
      "  Accuracy - Mean: 0.5500, Std: 0.0000\n",
      "  Nodes    - Mean: 63.00, Std: 0.00\n",
      "HiddenXORLV1Real:\n",
      "  Accuracy - Mean: 0.5438, Std: 0.0292\n",
      "  Nodes    - Mean: 15.81, Std: 0.70\n",
      "HiddenXORLV2Real:\n",
      "  Accuracy - Mean: 0.4684, Std: 0.0026\n",
      "  Nodes    - Mean: 19.40, Std: 0.73\n",
      "HiddenXORLV3Real:\n",
      "  Accuracy - Mean: 0.5331, Std: 0.0018\n",
      "  Nodes    - Mean: 17.40, Std: 0.73\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from typing import List, Dict\n",
    "from scipy.special import gammaln\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "class MCMCDecisionTree:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2, mcmc_iterations=1000, alpha_value=0.1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.mcmc_iterations = mcmc_iterations\n",
    "        self.tree = None\n",
    "        self.alpha_value = alpha_value\n",
    "\n",
    "    def _log_dirichlet(self, dirichlet_params):\n",
    "        return np.sum(gammaln(dirichlet_params)) - gammaln(np.sum(dirichlet_params))\n",
    "\n",
    "    def _evaluate_split(self, X, y, feature_index, threshold):\n",
    "        left_mask = X[:, feature_index] <= threshold\n",
    "        left_y, right_y = y[left_mask], y[~left_mask]\n",
    "        \n",
    "        if len(left_y) == 0 or len(right_y) == 0:\n",
    "            return -np.inf\n",
    "        \n",
    "        left_counts = np.zeros(len(self.classes_))\n",
    "        right_counts = np.zeros(len(self.classes_))\n",
    "        \n",
    "        for i, c in enumerate(self.classes_):\n",
    "            left_counts[i] = np.sum(left_y == c)\n",
    "            right_counts[i] = np.sum(right_y == c)\n",
    "        \n",
    "        alpha = np.ones(len(self.classes_)) * self.alpha_value\n",
    "        \n",
    "        log_likelihood = (\n",
    "            self._log_dirichlet(left_counts + alpha) - self._log_dirichlet(alpha) +\n",
    "            self._log_dirichlet(right_counts + alpha) - self._log_dirichlet(alpha)\n",
    "        )\n",
    "\n",
    "        log_prior = -(np.log2(4) + np.log2(X.shape[1]))*self.num_nodes()\n",
    "         \n",
    "        return log_likelihood + log_prior\n",
    "\n",
    "    def _mcmc_split(self, X, y):\n",
    "        n_features = X.shape[1]\n",
    "        current_feature = np.random.randint(0, n_features)\n",
    "        current_threshold = np.random.choice(X[:, current_feature])\n",
    "        current_score = self._evaluate_split(X, y, current_feature, current_threshold)\n",
    "        \n",
    "        best_feature, best_threshold, best_score = current_feature, current_threshold, current_score\n",
    "        \n",
    "        for _ in range(self.mcmc_iterations):\n",
    "            if np.random.random() < 0.5:\n",
    "                proposed_feature = np.random.randint(0, n_features)\n",
    "                proposed_threshold = np.random.choice(X[:, proposed_feature])\n",
    "            else:\n",
    "                proposed_feature = current_feature\n",
    "                proposed_threshold = current_threshold + np.random.normal(0, 0.1 * (np.max(X[:, current_feature]) - np.min(X[:, current_feature])))\n",
    "            \n",
    "            proposed_score = self._evaluate_split(X, y, proposed_feature, proposed_threshold)\n",
    "            \n",
    "            if np.isfinite(proposed_score) and np.isfinite(current_score):\n",
    "                acceptance_prob = min(1, np.exp(proposed_score - current_score))\n",
    "            elif np.isfinite(proposed_score):\n",
    "                acceptance_prob = 1\n",
    "            else:\n",
    "                acceptance_prob = 0\n",
    "            \n",
    "            if np.random.random() < acceptance_prob:\n",
    "                current_feature, current_threshold, current_score = proposed_feature, proposed_threshold, proposed_score\n",
    "                \n",
    "                if current_score > best_score:\n",
    "                    best_feature, best_threshold, best_score = current_feature, current_threshold, current_score\n",
    "        \n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        unique_classes = np.unique(y)\n",
    "\n",
    "        if depth >= self.max_depth or n_samples < self.min_samples_split or len(unique_classes) == 1:\n",
    "            counts = np.zeros(len(self.classes_))\n",
    "            for i, c in enumerate(self.classes_):\n",
    "                counts[i] = np.sum(y == c)\n",
    "            return Node(value=counts)\n",
    "\n",
    "        feature_index, threshold = self._mcmc_split(X, y)\n",
    "        \n",
    "        left_mask = X[:, feature_index] <= threshold\n",
    "        X_left, y_left = X[left_mask], y[left_mask]\n",
    "        X_right, y_right = X[~left_mask], y[~left_mask]\n",
    "        \n",
    "        left_subtree = self._grow_tree(X_left, y_left, depth + 1)\n",
    "        right_subtree = self._grow_tree(X_right, y_right, depth + 1)\n",
    "\n",
    "        return Node(feature_index=feature_index, threshold=threshold, left=left_subtree, right=right_subtree)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_features = X.shape[1]\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.n_classes = len(self.classes_)\n",
    "        print(f\"Number of classes: {self.n_classes}\")\n",
    "        print(f\"Unique classes: {self.classes_}\")\n",
    "        print(f\"Input y shape: {y.shape}\")\n",
    "        print(f\"Input y unique values: {np.unique(y)}\")\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "\n",
    "    def _predict_sample(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return self.classes_[np.argmax(node.value)]\n",
    "        \n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self._predict_sample(x, node.left)\n",
    "        else:\n",
    "            return self._predict_sample(x, node.right)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_sample(x, self.tree) for x in X])\n",
    "\n",
    "    def num_nodes(self):\n",
    "        return self._count_nodes(self.tree)\n",
    "\n",
    "    def _count_nodes(self, node):\n",
    "        if node is None:\n",
    "            return 0\n",
    "        return 1 + self._count_nodes(node.left) + self._count_nodes(node.right)\n",
    "\n",
    "def run_mcmc_dt_on_dataset(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    try:\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        mcmc_dt = MCMCDecisionTree(max_depth=5)\n",
    "        mcmc_dt.fit(X_train_scaled, y_train)\n",
    "\n",
    "        y_pred = mcmc_dt.predict(X_test_scaled)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        return accuracy, mcmc_dt.num_nodes()\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "    \n",
    "# ... [rest of the code remains the same] ...\n",
    "def experiment_on_datasets(seeds: List[int], n_trials: int=1, UCI: bool = False) -> Dict[str, Dict[str, float]]:\n",
    "\n",
    "    if UCI:\n",
    "        datasets = [\n",
    "            (17, \"BCW-D\"),\n",
    "            (109, \"Wine\"),\n",
    "            (53, \"Iris\"),\n",
    "            (850, \"Raisin\"),\n",
    "            ]\n",
    "    else:\n",
    "        # Specify CSV files directly\n",
    "        datasets = [\n",
    "            # (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor.csv\", \"HiddenXOR\"),\n",
    "            # (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/S1.csv\", \"BasicSanityCheck\"), \n",
    "            # (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/S2.csv\", \"HarderSanityCheck\")\n",
    "            (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_lv1.csv\", \"HiddenXORLV1\"),\n",
    "            (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_lv2.csv\", \"HiddenXORLV2\"),\n",
    "            (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_lv3.csv\", \"HiddenXORLV3\"),\n",
    "            (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_real_lv1.csv\", \"HiddenXORLV1Real\"),\n",
    "            (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_real_lv2.csv\", \"HiddenXORLV2Real\"),\n",
    "            (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_real_lv3.csv\", \"HiddenXORLV3Real\")\n",
    "        ]\n",
    "\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for dataset_info in datasets:\n",
    "        if UCI:\n",
    "            dataset_id, dataset_name = dataset_info\n",
    "            print(f\"\\nRunning experiment on {dataset_name} dataset...\")\n",
    "            dataset = fetch_ucirepo(id=dataset_id)\n",
    "            X = dataset.data.features.values\n",
    "            y = dataset.data.targets.values.ravel()\n",
    "        else:\n",
    "            file_path, dataset_name = dataset_info\n",
    "            print(f\"\\nRunning experiment on {dataset_name} dataset from {file_path}...\")\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"File {file_path} not found.\")\n",
    "                continue\n",
    "            data = pd.read_csv(file_path)\n",
    "            X = data.iloc[:, :-2].values  # Assuming last two columns are 'train'/'test' and the target\n",
    "            y = data.iloc[:, -2].values\n",
    "            split_column = data.iloc[:, -1].values  # 'train'/'test' column\n",
    "\n",
    "            # Split based on the 'train'/'test' column\n",
    "            X_train = X[split_column == 'train']\n",
    "            y_train = y[split_column == 'train']\n",
    "            X_test = X[split_column == 'test']\n",
    "            y_test = y[split_column == 'test']\n",
    "\n",
    "        print(f\"Original y shape: {y.shape}\")\n",
    "        print(f\"Original y unique values: {np.unique(y)}\")\n",
    "\n",
    "        if y.dtype == object:\n",
    "            le = LabelEncoder()\n",
    "            y = le.fit_transform(y)\n",
    "            print(f\"After LabelEncoder - y unique values: {np.unique(y)}\")\n",
    "        \n",
    "        print(f\"Dataset shape: {X.shape}\")\n",
    "        print(f\"Unique classes in dataset: {np.unique(y)}\")\n",
    "        \n",
    "        accuracies = []\n",
    "        n_nodes_list = []\n",
    "        for seed in seeds:\n",
    "            print(f\"\\nRunning with seed {seed}\")\n",
    "            if UCI: \n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "            accs, sizes = [], []\n",
    "            for _ in range(n_trials): \n",
    "                accuracy, n_nodes = run_mcmc_dt_on_dataset(X_train, y_train, X_test, y_test)\n",
    "                if accuracy is not None and n_nodes is not None:\n",
    "                    accs.append(accuracy)\n",
    "                    sizes.append(n_nodes)\n",
    "                accuracies.append(np.mean(accs))\n",
    "                n_nodes_list.append(np.mean(sizes))\n",
    "                print(f\"Seed {seed} - Accuracy: {np.mean(accs):.4f}, Nodes: {np.mean(sizes)}\")\n",
    "            if accuracy is not None and n_nodes is not None:\n",
    "                accuracies.append(accuracy)\n",
    "                n_nodes_list.append(n_nodes)\n",
    "                print(f\"Seed {seed} - Accuracy: {accuracy:.4f}, Nodes: {n_nodes}\")\n",
    "        \n",
    "        if accuracies and n_nodes_list:\n",
    "            mean_accuracy = np.mean(accuracies)\n",
    "            std_accuracy = np.std(accuracies)\n",
    "            mean_nodes = np.mean(n_nodes_list)\n",
    "            std_nodes = np.std(n_nodes_list)\n",
    "            \n",
    "            results[dataset_name] = {\n",
    "                \"mean_accuracy\": mean_accuracy,\n",
    "                \"std_accuracy\": std_accuracy,\n",
    "                \"mean_nodes\": mean_nodes,\n",
    "                \"std_nodes\": std_nodes\n",
    "            }\n",
    "            \n",
    "            print(f\"{dataset_name} - Mean Accuracy: {mean_accuracy:.4f}, Std: {std_accuracy:.4f}\")\n",
    "            print(f\"{dataset_name} - Mean Nodes: {mean_nodes:.2f}, Std: {std_nodes:.2f}\")\n",
    "        else:\n",
    "            print(f\"Failed to process {dataset_name} dataset\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the experiments\n",
    "np.random.seed(42)\n",
    "seeds = np.array([1])  # Using multiple seeds for more robust results\n",
    "results = experiment_on_datasets(seeds, n_trials=5)\n",
    "\n",
    "# Print final results\n",
    "print(\"\\nFinal Results:\")\n",
    "for dataset, metrics in results.items():\n",
    "    print(f\"{dataset}:\")\n",
    "    print(f\"  Accuracy - Mean: {metrics['mean_accuracy']:.4f}, Std: {metrics['std_accuracy']:.4f}\")\n",
    "    print(f\"  Nodes    - Mean: {metrics['mean_nodes']:.2f}, Std: {metrics['std_nodes']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HiddenXORLV1': {'mean_accuracy': 1.0,\n",
       "  'std_accuracy': 0.0,\n",
       "  'mean_nodes': 15.0,\n",
       "  'std_nodes': 0.0},\n",
       " 'HiddenXORLV2': {'mean_accuracy': 0.6266666666666668,\n",
       "  'std_accuracy': 1.1102230246251565e-16,\n",
       "  'mean_nodes': 55.0,\n",
       "  'std_nodes': 0.0},\n",
       " 'HiddenXORLV3': {'mean_accuracy': 0.5499999999999999,\n",
       "  'std_accuracy': 1.1102230246251565e-16,\n",
       "  'mean_nodes': 63.0,\n",
       "  'std_nodes': 0.0},\n",
       " 'HiddenXORLV1Real': {'mean_accuracy': 0.5438148148148149,\n",
       "  'std_accuracy': 0.02917674722917502,\n",
       "  'mean_nodes': 15.81111111111111,\n",
       "  'std_nodes': 0.6996471773969406},\n",
       " 'HiddenXORLV2Real': {'mean_accuracy': 0.4684074074074074,\n",
       "  'std_accuracy': 0.0025872961772700743,\n",
       "  'mean_nodes': 19.400000000000002,\n",
       "  'std_nodes': 0.7302967433402214},\n",
       " 'HiddenXORLV3Real': {'mean_accuracy': 0.5331296296296296,\n",
       "  'std_accuracy': 0.001780572648749831,\n",
       "  'mean_nodes': 17.400000000000002,\n",
       "  'std_nodes': 0.7302967433402214}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Synthetic Data Generation for testing** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Target  Split\n",
      "0          2          3          0          2          2       0  train\n",
      "1          3          0          0          2          1       0  train\n",
      "2          2          2          2          2          3       0  train\n",
      "3          0          3          3          3          2       0   test\n",
      "4          1          0          1          3          3       0  train\n",
      "5          1          1          1          3          3       0   test\n",
      "6          0          0          3          1          1       3  train\n",
      "7          0          3          0          0          2       0  train\n",
      "8          2          2          1          3          3       0  train\n",
      "9          3          3          2          1          1       0  train\n",
      "\n",
      "Feature distributions:\n",
      "         Feature_1    Feature_2    Feature_3    Feature_4    Feature_5\n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000\n",
      "mean      1.531000     1.428000     1.436000     1.525000     1.506000\n",
      "std       1.112779     1.109977     1.137188     1.140472     1.132805\n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000\n",
      "25%       1.000000     0.000000     0.000000     0.000000     0.000000\n",
      "50%       2.000000     1.000000     1.000000     2.000000     2.000000\n",
      "75%       3.000000     2.000000     2.000000     3.000000     3.000000\n",
      "max       3.000000     3.000000     3.000000     3.000000     3.000000\n",
      "\n",
      "Target distribution:\n",
      "Target\n",
      "0    0.760\n",
      "3    0.086\n",
      "2    0.080\n",
      "1    0.074\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic data\n",
    "n_samples = 1000\n",
    "n_features = 5\n",
    "n_classes = 4\n",
    "\n",
    "# Generate features\n",
    "X = np.random.randint(0, 4, size=(n_samples, n_features))\n",
    "\n",
    "# Generate target variable with some noise\n",
    "y = np.zeros(n_samples, dtype=int)\n",
    "y[(X[:, 0] == 0) & (X[:, 1] == 1)] = 0\n",
    "y[(X[:, 0] == 1) & (X[:, 2] == 2)] = 1\n",
    "y[(X[:, 1] == 2) & (X[:, 3] == 0)] = 2\n",
    "y[(X[:, 2] == 3) & (X[:, 4] == 1)] = 3\n",
    "\n",
    "# Add some noise\n",
    "noise = np.random.rand(n_samples) < 0.1\n",
    "y[noise] = np.random.randint(0, 4, size=sum(noise))\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(X, columns=[f'Feature_{i+1}' for i in range(n_features)])\n",
    "df['Target'] = y\n",
    "\n",
    "# Split into train and test\n",
    "train_mask = np.random.rand(len(df)) < 0.8\n",
    "df['Split'] = np.where(train_mask, 'train', 'test')\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/S2.csv', index=False)\n",
    "\n",
    "print(df.head(10))\n",
    "print(\"\\nFeature distributions:\")\n",
    "print(df[['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5']].describe())\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(df['Target'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Potentially Updated SMC Code** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running experiment on Wine dataset...\n",
      "\n",
      "Running with seed 1\n",
      "Number of classes: 3\n",
      "Unique classes: [1 2 3]\n",
      "Input y shape: (142,)\n",
      "Input y unique values: [1 2 3]\n",
      "Log Posterior of the fitted tree: -100.44632524007334\n",
      "Seed 1 - Accuracy: 0.6389, Nodes: 3.0\n",
      "Wine - Mean Accuracy: 0.6389, Std: 0.0000\n",
      "Wine - Mean Nodes: 3.00, Std: 0.00\n",
      "\n",
      "Final Results:\n",
      "Wine:\n",
      "  Accuracy - Mean: 0.6389, Std: 0.0000\n",
      "  Nodes    - Mean: 3.00, Std: 0.00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from typing import List, Dict\n",
    "from scipy.special import gammaln\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "class SMCDecisionTree:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2, n_particles=10, alpha_value=0.1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.n_particles = n_particles\n",
    "        self.tree = None\n",
    "        self.alpha_value = alpha_value\n",
    "\n",
    "    def _log_dirichlet(self, dirichlet_params):\n",
    "        return np.sum(gammaln(dirichlet_params)) - gammaln(np.sum(dirichlet_params)) \n",
    "\n",
    "    def _initialize_particles(self, n_features):\n",
    "        return {\n",
    "            'feature_index': np.random.randint(0, n_features, self.n_particles),\n",
    "            'threshold': np.random.uniform(0, 1, self.n_particles)\n",
    "        }\n",
    "\n",
    "    def _move_particles(self, particles, n_features):\n",
    "        move_mask = np.random.random(self.n_particles) < 0.5\n",
    "        particles['feature_index'][move_mask] = np.random.randint(0, n_features, np.sum(move_mask))\n",
    "        particles['threshold'][~move_mask] += np.random.normal(0, 0.1, np.sum(~move_mask))\n",
    "        return particles\n",
    "\n",
    "    def _evaluate_split(self, X, y, feature_index, threshold):\n",
    "        left_mask = X[:, feature_index] <= threshold\n",
    "        left_y, right_y = y[left_mask], y[~left_mask]\n",
    "        \n",
    "        if len(left_y) == 0 or len(right_y) == 0:\n",
    "            return -np.inf\n",
    "        \n",
    "        left_counts = np.zeros(len(self.classes_))\n",
    "        right_counts = np.zeros(len(self.classes_))\n",
    "        \n",
    "        for i, c in enumerate(self.classes_):\n",
    "            left_counts[i] = np.sum(left_y == c)\n",
    "            right_counts[i] = np.sum(right_y == c)\n",
    "        \n",
    "        alpha = np.ones(len(self.classes_)) * self.alpha_value\n",
    "        \n",
    "        log_likelihood = (\n",
    "            self._log_dirichlet(left_counts + alpha) - self._log_dirichlet(alpha) +\n",
    "            self._log_dirichlet(right_counts + alpha) - self._log_dirichlet(alpha)\n",
    "        )\n",
    "        \n",
    "        log_prior = 0 #-(np.log2(4) + np.log2(X.shape[1]))*self.num_internal_nodes() \n",
    "        return log_likelihood + log_prior\n",
    "\n",
    "    def _smc_split(self, X, y):\n",
    "        particles = self._initialize_particles(X.shape[1])\n",
    "        \n",
    "        for _ in range(20):  # Number of SMC iterations\n",
    "            particles = self._move_particles(particles, X.shape[1])\n",
    "            \n",
    "            weights = np.array([self._evaluate_split(X, y, p_f, p_t) \n",
    "                                for p_f, p_t in zip(particles['feature_index'], particles['threshold'])])\n",
    "            weights = np.where(np.isfinite(weights), np.exp(weights), 0)\n",
    "            \n",
    "            # Handle potential zero sum of weights\n",
    "            if np.sum(weights) == 0:\n",
    "                weights = np.ones_like(weights) / len(weights)\n",
    "            else:\n",
    "                weights /= np.sum(weights)\n",
    "            \n",
    "            # Check for NaN values and replace with uniform probabilities if necessary\n",
    "            if np.any(np.isnan(weights)):\n",
    "                print(\"Warning: NaN weights encountered. Using uniform probabilities.\")\n",
    "                weights = np.ones_like(weights) / len(weights)\n",
    "            \n",
    "            indices = np.random.choice(self.n_particles, size=self.n_particles, p=weights)\n",
    "            particles = {k: v[indices] for k, v in particles.items()}\n",
    "        \n",
    "        best_index = np.argmax(weights)\n",
    "        return particles['feature_index'][best_index], particles['threshold'][best_index]\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        unique_classes = np.unique(y)\n",
    "\n",
    "        if depth >= self.max_depth or n_samples < self.min_samples_split or len(unique_classes) == 1:\n",
    "            counts = np.zeros(len(self.classes_))\n",
    "            for i, c in enumerate(self.classes_):\n",
    "                counts[i] = np.sum(y == c)\n",
    "            return Node(value=counts)\n",
    "\n",
    "        feature_index, threshold = self._smc_split(X, y)\n",
    "        \n",
    "        left_mask = X[:, feature_index] <= threshold\n",
    "        X_left, y_left = X[left_mask], y[left_mask]\n",
    "        X_right, y_right = X[~left_mask], y[~left_mask]\n",
    "        \n",
    "        left_subtree = self._grow_tree(X_left, y_left, depth + 1)\n",
    "        right_subtree = self._grow_tree(X_right, y_right, depth + 1)\n",
    "\n",
    "        return Node(feature_index=feature_index, threshold=threshold, left=left_subtree, right=right_subtree)\n",
    "\n",
    "    def _compute_log_posterior(self, node, alpha):\n",
    "        if node is None:\n",
    "            return 0\n",
    "        \n",
    "        if node.value is not None:\n",
    "            # Leaf node\n",
    "            counts = node.value\n",
    "            log_likelihood = self._log_dirichlet(counts + alpha) - self._log_dirichlet(alpha)\n",
    "            log_prior = 0 # -(np.log2(4) + np.log2(self.n_features)) * self.num_internal_nodes()\n",
    "            return log_likelihood + log_prior\n",
    "        \n",
    "        left_log_post = self._compute_log_posterior(node.left, alpha)\n",
    "        right_log_post = self._compute_log_posterior(node.right, alpha)\n",
    "        \n",
    "        return left_log_post + right_log_post\n",
    "\n",
    "    def log_posterior(self):\n",
    "        alpha = np.ones(len(self.classes_)) * self.alpha_value\n",
    "        return self._compute_log_posterior(self.tree, alpha) \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_features = X.shape[1]\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.n_classes = len(self.classes_)\n",
    "        print(f\"Number of classes: {self.n_classes}\")\n",
    "        print(f\"Unique classes: {self.classes_}\")\n",
    "        print(f\"Input y shape: {y.shape}\")\n",
    "        print(f\"Input y unique values: {np.unique(y)}\")\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "        log_posterior = self.log_posterior()\n",
    "        print(f\"Log Posterior of the fitted tree: {log_posterior}\")\n",
    "\n",
    "    def _predict_sample(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return self.classes_[np.argmax(node.value)]\n",
    "        \n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self._predict_sample(x, node.left)\n",
    "        else:\n",
    "            return self._predict_sample(x, node.right)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_sample(x, self.tree) for x in X])\n",
    "\n",
    "    def num_nodes(self):\n",
    "        return self._count_nodes(self.tree)\n",
    "\n",
    "    def _count_nodes(self, node):\n",
    "        if node is None:\n",
    "            return 0\n",
    "        return 1 + self._count_nodes(node.left) + self._count_nodes(node.right)\n",
    "\n",
    "    def _count_internal_nodes(self, node):\n",
    "        if node is None or (node.left is None and node.right is None):\n",
    "            return 0\n",
    "        return 1 + self._count_internal_nodes(node.left) + self._count_internal_nodes(node.right)\n",
    "\n",
    "    def num_internal_nodes(self):\n",
    "        return self._count_internal_nodes(self.tree)\n",
    "\n",
    "def run_smc_dt_on_dataset(X_train, y_train, X_test, y_test, max_depth=5, n_particles=100, seed=42):\n",
    "    try:\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        smc_dt = SMCDecisionTree(max_depth=max_depth, n_particles=n_particles)\n",
    "        smc_dt.fit(X_train_scaled, y_train)\n",
    "\n",
    "        y_pred = smc_dt.predict(X_test_scaled)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        return accuracy, smc_dt.num_nodes()\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "def experiment_on_datasets(seeds: List[int], n_trials=10, UCI=True) -> Dict[str, Dict[str, float]]:\n",
    "    if UCI:\n",
    "        datasets = [\n",
    "            # (17, \"BCW-D\"),\n",
    "            (109, \"Wine\"),\n",
    "            # (53, \"Iris\"),\n",
    "            # (850, \"Raisin\"),\n",
    "        ]\n",
    "    else:\n",
    "        # Specify CSV files directly\n",
    "        datasets = [\n",
    "            # (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor.csv\", \"HiddenXOR\"),\n",
    "            # (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/S1.csv\", \"BasicSanityCheck\"), \n",
    "            # (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/S2.csv\", \"HarderSanityCheck\")\n",
    "            (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_lv1.csv\", \"HiddenXORLV1\"),\n",
    "            (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_lv2.csv\", \"HiddenXORLV2\"),\n",
    "            (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_lv3.csv\", \"HiddenXORLV3\"),\n",
    "            (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_real_lv1.csv\", \"HiddenXORLV1Real\"),\n",
    "            (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_real_lv2.csv\", \"HiddenXORLV2Real\"),\n",
    "            (\"/Users/momac18/Dropbox/Mac/Desktop/CodeBases/RF-GFN/RF-GFN/baselines/data/hidden_xor_real_lv3.csv\", \"HiddenXORLV3Real\")\n",
    "        ]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for dataset_info in datasets:\n",
    "        if UCI:\n",
    "            dataset_id, dataset_name = dataset_info\n",
    "            print(f\"\\nRunning experiment on {dataset_name} dataset...\")\n",
    "            dataset = fetch_ucirepo(id=dataset_id)\n",
    "            X = dataset.data.features.values\n",
    "            y = dataset.data.targets.values.ravel()\n",
    "        else:\n",
    "            file_path, dataset_name = dataset_info\n",
    "            print(f\"\\nRunning experiment on {dataset_name} dataset from {file_path}...\")\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"File {file_path} not found.\")\n",
    "                continue\n",
    "            data = pd.read_csv(file_path)\n",
    "            X = data.iloc[:, :-2].values  # Assuming last two columns are 'train'/'test' and the target\n",
    "            y = data.iloc[:, -2].values\n",
    "            split_column = data.iloc[:, -1].values  # 'train'/'test' column\n",
    "\n",
    "            # Split based on the 'train'/'test' column\n",
    "            X_train = X[split_column == 'train']\n",
    "            y_train = y[split_column == 'train']\n",
    "            X_test = X[split_column == 'test']\n",
    "            y_test = y[split_column == 'test']\n",
    "\n",
    "        # print(f\"Original y shape: {y.shape}\")\n",
    "        # print(f\"Original y unique values: {np.unique(y)}\")\n",
    "        \n",
    "        # print(f\"Dataset shape: {X.shape}\")\n",
    "        # print(f\"Unique classes in dataset: {np.unique(y)}\")\n",
    "        \n",
    "        accuracies = []\n",
    "        n_nodes_list = []\n",
    "        for seed in seeds:\n",
    "            print(f\"\\nRunning with seed {seed}\")\n",
    "            if UCI: \n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "            \n",
    "            if y_train.dtype == object:\n",
    "                le = LabelEncoder()\n",
    "                y_train = le.fit_transform(y_train)\n",
    "                y_test = le.transform(y_test)\n",
    "                # print(f\"After LabelEncoder - y_train unique values: {np.unique(y_train)}\")\n",
    "                # print(f\"After LabelEncoder - y_test unique values: {np.unique(y_test)}\")\n",
    "            try:\n",
    "                accs, sizes = [], []\n",
    "                for _ in range(n_trials):\n",
    "                    accuracy, n_nodes = run_smc_dt_on_dataset(X_train, y_train, X_test, y_test, seed)\n",
    "                    if accuracy is not None and n_nodes is not None:\n",
    "                        accs.append(accuracy)\n",
    "                        sizes.append(n_nodes)\n",
    "                    accuracies.append(np.mean(accs))\n",
    "                    n_nodes_list.append(np.mean(sizes))\n",
    "                    print(f\"Seed {seed} - Accuracy: {np.mean(accs):.4f}, Nodes: {np.mean(sizes)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred with seed {seed}: {str(e)}\")\n",
    "        \n",
    "        if accuracies and n_nodes_list:\n",
    "            mean_accuracy = np.mean(accuracies)\n",
    "            std_accuracy = np.std(accuracies)\n",
    "            mean_nodes = np.mean(n_nodes_list)\n",
    "            std_nodes = np.std(n_nodes_list)\n",
    "            \n",
    "            results[dataset_name] = {\n",
    "                \"mean_accuracy\": mean_accuracy,\n",
    "                \"std_accuracy\": std_accuracy,\n",
    "                \"mean_nodes\": mean_nodes,\n",
    "                \"std_nodes\": std_nodes\n",
    "            }\n",
    "            \n",
    "            print(f\"{dataset_name} - Mean Accuracy: {mean_accuracy:.4f}, Std: {std_accuracy:.4f}\")\n",
    "            print(f\"{dataset_name} - Mean Nodes: {mean_nodes:.2f}, Std: {std_nodes:.2f}\")\n",
    "        else:\n",
    "            print(f\"Failed to process {dataset_name} dataset\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the experiments\n",
    "seeds = np.array([1])  # Using multiple seeds for more robust results\n",
    "results = experiment_on_datasets(seeds, n_trials=1, UCI=True)\n",
    "\n",
    "# Print final results\n",
    "print(\"\\nFinal Results:\")\n",
    "for dataset, metrics in results.items():\n",
    "    print(f\"{dataset}:\")\n",
    "    print(f\"  Accuracy - Mean: {metrics['mean_accuracy']:.4f}, Std: {metrics['std_accuracy']:.4f}\")\n",
    "    print(f\"  Nodes    - Mean: {metrics['mean_nodes']:.2f}, Std: {metrics['std_nodes']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
